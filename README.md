Этот код включает в себя все необходимое для поддержки формата OpenAI API, сохраняя при этом оригинальную функциональность RKLLM. Вот краткое описание основных изменений:

Добавлен новый маршрут /v1/chat/completions, который обрабатывает запросы в формате OpenAI API.
Реализована поддержка как потоковых (stream), так и непотоковых ответов.
Добавлена функция num_tokens_from_string для подсчета токенов (требуется установка библиотеки tiktoken).
Ответы форматируются в соответствии с форматом OpenAI API, включая идентификаторы, временные метки и информацию об использовании токенов.
Обработка ошибок приведена в соответствие с форматом OpenAI API.
Чтобы использовать этот обновленный сервер:

Установите дополнительную библиотеку: pip install tiktoken
Запустите скрипт с теми же аргументами командной строки, что и раньше:
text

python script.py --target_platform rk3588 --rkllm_model_path /path/to/your/model
Теперь вы можете отправлять запросы к /v1/chat/completions в формате, совместимом с OpenAI API.
Этот обновленный сервер теперь должен быть совместим с большинством клиентских библиотек и инструментов, разработанных для работы с OpenAI API, сохраняя при этом специфическую функциональность RKLLM.
