# RKLLM Server с поддержкой OpenAI API

Этот код включает в себя все необходимое для поддержки формата OpenAI API, сохраняя при этом оригинальную функциональность RKLLM.

## Основные изменения

1. Добавлен новый маршрут `/v1/chat/completions`, который обрабатывает запросы в формате OpenAI API.
2. Реализована поддержка как потоковых (stream), так и непотоковых ответов.
3. Добавлена функция `num_tokens_from_string` для подсчета токенов (требуется установка библиотеки `tiktoken`).
4. Ответы форматируются в соответствии с форматом OpenAI API, включая идентификаторы, временные метки и информацию об использовании токенов.
5. Обработка ошибок приведена в соответствие с форматом OpenAI API.

## Использование

Чтобы использовать этот обновленный сервер:

1. Установите дополнительную библиотеку:
   ```
   pip install tiktoken
   ```

2. Запустите скрипт с теми же аргументами командной строки, что и раньше:
   ```
   python rkllmserver.py --target_platform rk3588 --rkllm_model_path /path/to/your/model
   ```

3. Теперь вы можете отправлять запросы к `/v1/chat/completions` в формате, совместимом с OpenAI API.

## Совместимость

Этот обновленный сервер теперь должен быть совместим с большинством клиентских библиотек и инструментов, разработанных для работы с OpenAI API, сохраняя при этом специфическую функциональность RKLLM.
